"""
1. Optuna å¯åŠ¨ä¸€æ¬¡è¯•éªŒã€‚
2. è¯•éªŒè°ƒç”¨ cross_validate å‡½æ•°å¼€å§‹ 5 æŠ˜äº¤å‰éªŒè¯ã€‚
3. Fold 1:
   a. åˆ’åˆ† Fold 1 çš„ train_data (80%) å’Œ val_data (20%)ã€‚
   b. å½’ä¸€åŒ– train_data å’Œ val_dataã€‚
   c. å¯åŠ¨ VACWGAN æ¨¡å—è¿›è¡Œæ•°æ®å¢å¼º:
      i.   åŠ è½½ Fold 1 ä¸“å±çš„ GAN å‚æ•°ã€‚
      ii.  åœ¨ Fold 1 çš„ train_data ä¸Šè®­ç»ƒ GANã€‚
      iii. ç”Ÿæˆ (syn_spec, syn_env) æ ·æœ¬ä»¥å¹³è¡¡ train_dataã€‚
      iv.  è¿”å›å¢å¼ºåçš„ aug_train_dataã€‚
   d. åˆ†ç±»å™¨è®­ç»ƒ:
      i.   ä½¿ç”¨ aug_train_data è®­ç»ƒ MultiFeatureFusionModelã€‚
      ii.  ä½¿ç”¨ val_data è¯„ä¼°æ¨¡å‹ï¼Œå¾—åˆ° acc_1ã€‚
5. Fold 2:
   a. ...
   c. [æ•°æ®å¢å¼º]:
      i.   åŠ è½½ Fold 2 ä¸“å±çš„ GAN å‚æ•°ã€‚
   ...
6. Fold 5: é‡å¤...
7. è®¡ç®— 5 æŠ˜çš„ mean_accï¼Œå°†å…¶ä½œä¸º Optuna çš„è¯„ä¼°åˆ†æ•°ã€‚
8. TopKTracker è·Ÿè¸ªå¹¶ä¿å­˜æœ€ä½³æ¨¡å‹ã€‚
"""

import os
import pickle
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset, Dataset
from sklearn.model_selection import StratifiedKFold
from pathlib import Path
from datetime import datetime
import json
import optuna
from collections import Counter
import warnings

warnings.filterwarnings('ignore')

"""é…ç½®å‚æ•°"""
DATASET_PATH = "optimized_features_dataset.pkl"

# ä¼˜åŒ–é…ç½®
N_TRIALS = 50  # Optuna è¯•éªŒæ¬¡æ•°
N_FOLDS = 5  # äº¤å‰éªŒè¯æŠ˜æ•°
TRAIN_EPOCHS = 100  # åˆ†ç±»å™¨è®­ç»ƒè½®æ•°
EARLY_STOPPING_PATIENCE = 10  # æ—©åœå¹…åº¦
TOP_K_MODELS = 5  # ä¿å­˜Top-5æ¨¡å‹

# æ•°æ®å¢å¼ºé…ç½®
GAN_EPOCHS = 100  # æ¯ä¸€æŠ˜è®­ç»ƒGANçš„è½®æ•°
FOLD_SPECIFIC_GAN_PARAMS = [
    # --- Fold 1 (ç´¢å¼• 0) ---
    {'latent_dim': 96, 'lr': 0.0008809783391095071, 'd_iters': 4, 'lambda_cls': 7.2824335524798745, 'lambda_kl': 1.4669130637900507},

    # --- Fold 2 (ç´¢å¼• 1) ---
    {'latent_dim': 192, 'lr': 9.333635381796446e-05, 'd_iters': 7, 'lambda_cls': 19.950858751074374, 'lambda_kl': 1.0697610228678371},

    # --- Fold 3 (ç´¢å¼• 2) ---
    {'latent_dim': 160, 'lr': 0.0002427050090622415, 'd_iters': 3, 'lambda_cls': 9.898693858628008, 'lambda_kl': 1.633001343548243},

    # --- Fold 4 (ç´¢å¼• 3) ---
    {'latent_dim': 192, 'lr': 9.792715480227e-05, 'd_iters': 3, 'lambda_cls': 13.785436683742514, 'lambda_kl': 1.3301469032381479},

    # --- Fold 5 (ç´¢å¼• 4) ---
    {'latent_dim': 160, 'lr': 0.00017586959251670548, 'd_iters': 5, 'lambda_cls': 8.664599779776182, 'lambda_kl': 0.33742629946541564}
]

"""ç¬¬ 1 éƒ¨åˆ†: VACWGAN æ•°æ®å¢å¼ºæ¨¡å—"""


class MultiModalDataset(Dataset):
    """å¤šæ¨¡æ€æ•°æ®é›†"""

    def __init__(self, x_spec, x_env, y):
        self.x_spec = torch.FloatTensor(x_spec)
        self.x_env = torch.FloatTensor(x_env)
        self.y = torch.LongTensor(y)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return self.x_spec[idx], self.x_env[idx], self.y[idx]


class MultiModalEncoder(nn.Module):
    """å¤šæ¨¡æ€ç¼–ç å™¨ï¼Œå¤„ç† spec å’Œ env ä¸¤ä¸ªè¾“å…¥"""

    def __init__(self, latent_dim=128):
        super(MultiModalEncoder, self).__init__()
        # Specåˆ†æ”¯: (7, 48) -> feature
        self.spec_branch = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(32),
            nn.LeakyReLU(0.2),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # (64, 4, 24)
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # (128, 2, 12)
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2),
            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),  # (256, 1, 6)
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2),
        )
        # Envåˆ†æ”¯: (5, 32) -> feature
        self.env_branch = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(32),
            nn.LeakyReLU(0.2),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # (64, 3, 16)
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # (128, 2, 8)
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2),
            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),  # (256, 1, 4)
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2),
        )
        self.spec_flat_dim = 256 * 1 * 6
        self.env_flat_dim = 256 * 1 * 4
        self.combined_dim = self.spec_flat_dim + self.env_flat_dim
        self.fusion_fc = nn.Sequential(
            nn.Linear(self.combined_dim, 512),
            nn.BatchNorm1d(512),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.LeakyReLU(0.2),
        )
        self.fc_mu = nn.Linear(256, latent_dim)
        self.fc_logvar = nn.Linear(256, latent_dim)

    def forward(self, x_spec, x_env):
        x_spec = x_spec.unsqueeze(1)
        x_env = x_env.unsqueeze(1)
        spec_feat = self.spec_branch(x_spec)
        env_feat = self.env_branch(x_env)
        spec_feat = spec_feat.view(spec_feat.size(0), -1)
        env_feat = env_feat.view(env_feat.size(0), -1)
        # L2 å½’ä¸€åŒ–ä»¥ç¼“è§£æ¨¡æ€ä¸»å¯¼
        spec_feat = F.normalize(spec_feat, p=2, dim=1)
        env_feat = F.normalize(env_feat, p=2, dim=1)
        combined = torch.cat([spec_feat, env_feat], dim=1)
        fused = self.fusion_fc(combined)
        mu = self.fc_mu(fused)
        logvar = self.fc_logvar(fused)
        return mu, logvar


class MultiModalGenerator(nn.Module):
    """å¤šæ¨¡æ€ç”Ÿæˆå™¨ï¼Œç”Ÿæˆ spec å’Œ env ä¸¤ä¸ªè¾“å‡º"""

    def __init__(self, latent_dim=128, num_classes=10):
        super(MultiModalGenerator, self).__init__()
        self.latent_dim = latent_dim
        self.label_embedding = nn.Embedding(num_classes, latent_dim)
        self.shared_trunk = nn.Sequential(
            nn.Linear(latent_dim * 2, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(True),
            nn.Linear(512, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(True),
        )
        self.spec_fc = nn.Sequential(
            nn.Linear(1024, 256 * 2 * 6),
            nn.BatchNorm1d(256 * 2 * 6),
            nn.ReLU(True),
        )
        self.spec_deconv = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(True),
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(True),
            nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(True),
            nn.Conv2d(32, 1, kernel_size=3, stride=1, padding=1),
            nn.Tanh()
        )
        self.env_fc = nn.Sequential(
            nn.Linear(1024, 256 * 2 * 4),
            nn.BatchNorm1d(256 * 2 * 4),
            nn.ReLU(True),
        )
        self.env_deconv = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(True),
            nn.ConvTranspose2d(128, 64, kernel_size=(3, 4), stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(True),
            nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(True),
            nn.Conv2d(32, 1, kernel_size=3, stride=1, padding=1),
            nn.Tanh()
        )

    def forward(self, z, labels):
        c_emb = self.label_embedding(labels)
        z_c = torch.cat([z, c_emb], dim=1)
        shared = self.shared_trunk(z_c)
        spec_feat = self.spec_fc(shared)
        spec_feat = spec_feat.view(-1, 256, 2, 6)
        spec_out = self.spec_deconv(spec_feat)
        spec_out = F.interpolate(spec_out, size=(7, 48), mode='bilinear', align_corners=False)
        env_feat = self.env_fc(shared)
        env_feat = env_feat.view(-1, 256, 2, 4)
        env_out = self.env_deconv(env_feat)
        env_out = F.interpolate(env_out, size=(5, 32), mode='bilinear', align_corners=False)
        return spec_out.squeeze(1), env_out.squeeze(1)


class MultiModalDiscriminator(nn.Module):
    """å¤šæ¨¡æ€åˆ¤åˆ«å™¨"""

    def __init__(self):
        super(MultiModalDiscriminator, self).__init__()
        self.spec_branch = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2),
        )
        self.env_branch = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2),
        )
        self.spec_feat_dim = 128 * 1 * 6
        self.env_feat_dim = 128 * 1 * 4
        self.adv_layer = nn.Sequential(
            nn.Linear(self.spec_feat_dim + self.env_feat_dim, 256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(256, 1)
        )

    def forward(self, x_spec, x_env):
        x_spec = x_spec.unsqueeze(1)
        x_env = x_env.unsqueeze(1)
        spec_feat = self.spec_branch(x_spec)
        env_feat = self.env_branch(x_env)
        spec_feat = spec_feat.view(spec_feat.size(0), -1)
        env_feat = env_feat.view(env_feat.size(0), -1)
        spec_feat = F.normalize(spec_feat, p=2, dim=1)
        env_feat = F.normalize(env_feat, p=2, dim=1)
        combined = torch.cat([spec_feat, env_feat], dim=1)
        validity = self.adv_layer(combined)
        return validity


class GAN_MultiModalClassifier(nn.Module):
    """å¤šæ¨¡æ€åˆ†ç±»å™¨"""

    def __init__(self, num_classes=10):
        super(GAN_MultiModalClassifier, self).__init__()
        self.spec_branch = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2),
        )
        self.env_branch = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2),
        )
        self.spec_feat_dim = 128 * 1 * 6
        self.env_feat_dim = 128 * 1 * 4
        self.classification_layer = nn.Sequential(
            nn.Linear(self.spec_feat_dim + self.env_feat_dim, 256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )

    def forward(self, x_spec, x_env):
        x_spec = x_spec.unsqueeze(1)
        x_env = x_env.unsqueeze(1)
        spec_feat = self.spec_branch(x_spec)
        env_feat = self.env_branch(x_env)
        spec_feat = spec_feat.view(spec_feat.size(0), -1)
        env_feat = env_feat.view(env_feat.size(0), -1)
        spec_feat = F.normalize(spec_feat, p=2, dim=1)
        env_feat = F.normalize(env_feat, p=2, dim=1)
        combined = torch.cat([spec_feat, env_feat], dim=1)
        class_output = self.classification_layer(combined)
        return class_output


def reparameterization(mu, logvar):
    """é‡å‚æ•°åŒ–"""
    std = torch.exp(0.5 * logvar)
    eps = torch.randn_like(std)
    return mu + eps * std


def compute_gradient_penalty(D, real_spec, real_env, fake_spec, fake_env, device, gamma=10):
    """è®¡ç®—æ¢¯åº¦æƒ©ç½š"""
    batch_size = real_spec.size(0)
    alpha_spec = torch.rand(batch_size, 1, 1).to(device)
    alpha_env = torch.rand(batch_size, 1, 1).to(device)
    interpolates_spec = (alpha_spec * real_spec + (1 - alpha_spec) * fake_spec).requires_grad_(True)
    interpolates_env = (alpha_env * real_env + (1 - alpha_env) * fake_env).requires_grad_(True)
    d_interpolates = D(interpolates_spec, interpolates_env)
    fake = torch.ones(batch_size, 1, device=device).requires_grad_(False)
    gradients = torch.autograd.grad(
        outputs=d_interpolates,
        inputs=[interpolates_spec, interpolates_env],
        grad_outputs=fake,
        create_graph=True,
        retain_graph=True,
        only_inputs=True,
    )
    gradients_spec = gradients[0].view(batch_size, -1)
    gradients_env = gradients[1].view(batch_size, -1)
    gradients_combined = torch.cat([gradients_spec, gradients_env], dim=1)
    gradient_penalty = ((gradients_combined.norm(2, dim=1) - 1) ** 2).mean() * gamma
    return gradient_penalty


def compute_kl_loss(mu, logvar):
    """è®¡ç®—KLæ•£åº¦"""
    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / mu.size(0)
    return kl_loss


def train_vacwgan(data_loader, num_classes, device, params, epochs=100):
    """è®­ç»ƒå¤šæ¨¡æ€ VACWGAN"""
    # ä»ä¼ å…¥çš„ params å­—å…¸ä¸­è§£åŒ…å‚æ•°
    latent_dim = params['latent_dim']
    lr = params['lr']
    d_iters = params['d_iters']
    lambda_cls = params['lambda_cls']
    lambda_kl = params['lambda_kl']

    E = MultiModalEncoder(latent_dim=latent_dim).to(device)
    G = MultiModalGenerator(latent_dim=latent_dim, num_classes=num_classes).to(device)
    D = MultiModalDiscriminator().to(device)
    C = GAN_MultiModalClassifier(num_classes=num_classes).to(device)

    opt_E = optim.Adam(E.parameters(), lr=lr, betas=(0.5, 0.999))
    opt_G = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))
    opt_D = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))
    opt_C = optim.Adam(C.parameters(), lr=lr, betas=(0.5, 0.999))

    ce_loss = nn.CrossEntropyLoss()

    for epoch in range(epochs):
        E.train()
        G.train()
        D.train()
        C.train()
        for i, (real_spec, real_env, labels) in enumerate(data_loader):
            real_spec = real_spec.to(device)
            real_env = real_env.to(device)
            labels = labels.to(device)
            opt_D.zero_grad()
            opt_C.zero_grad()
            d_real = D(real_spec, real_env)
            c_real = C(real_spec, real_env)
            loss_D_real = -torch.mean(d_real)
            loss_C_real = ce_loss(c_real, labels)
            mu, logvar = E(real_spec, real_env)
            z = reparameterization(mu, logvar)
            fake_spec, fake_env = G(z, labels)
            fake_spec_d, fake_env_d = fake_spec.detach(), fake_env.detach()
            d_fake = D(fake_spec_d, fake_env_d)
            c_fake = C(fake_spec_d, fake_env_d)
            loss_D_fake = torch.mean(d_fake)
            loss_C_fake = ce_loss(c_fake, labels)
            gp = compute_gradient_penalty(D, real_spec, real_env,
                                          fake_spec_d, fake_env_d, device)
            loss_D = loss_D_fake + loss_D_real + gp
            loss_C = loss_C_real + loss_C_fake
            loss_D.backward(retain_graph=True)
            loss_C.backward()
            opt_D.step()
            opt_C.step()
            if i % d_iters == 0:
                opt_G.zero_grad()
                opt_E.zero_grad()
                mu, logvar = E(real_spec, real_env)
                z = reparameterization(mu, logvar)
                fake_spec, fake_env = G(z, labels)
                d_fake_g = D(fake_spec, fake_env)
                c_fake_g = C(fake_spec, fake_env)
                loss_G_adv = -torch.mean(d_fake_g)
                loss_G_cls = ce_loss(c_fake_g, labels)
                loss_E_kl = compute_kl_loss(mu, logvar)
                loss_G_total = loss_G_adv + lambda_cls * loss_G_cls + lambda_kl * loss_E_kl
                loss_G_total.backward()
                opt_G.step()
                opt_E.step()
        if (epoch + 1) % 50 == 0:
            print(f"    [GAN Epoch {epoch + 1}/{epochs}] G_Loss: {loss_G_total.item():.4f}, D_Loss: {loss_D.item():.4f}")

    return E, G, D, C


def generate_synthetic_samples(E, G, x_spec_minority, x_env_minority, y_minority, num_to_generate, device):
    """ç”Ÿæˆåˆæˆæ ·æœ¬"""
    if len(y_minority) == 0 or num_to_generate == 0:
        return np.array([]), np.array([]), np.array([])

    minority_dataset = MultiModalDataset(x_spec_minority, x_env_minority, y_minority)
    minority_loader = DataLoader(minority_dataset, batch_size=min(len(y_minority), 64), shuffle=True)

    synthetic_spec_list = []
    synthetic_env_list = []
    current_generated = 0

    E.eval()
    G.eval()

    with torch.no_grad():
        while current_generated < num_to_generate:
            for spec_inputs, env_inputs, labels in minority_loader:
                spec_inputs = spec_inputs.to(device)
                env_inputs = env_inputs.to(device)
                labels = labels.to(device)
                mu, logvar = E(spec_inputs, env_inputs)
                z = reparameterization(mu, logvar)
                fake_spec, fake_env = G(z, labels)
                fake_spec = fake_spec.cpu().numpy()
                fake_env = fake_env.cpu().numpy()
                num_batch = fake_spec.shape[0]
                if current_generated + num_batch > num_to_generate:
                    needed = num_to_generate - current_generated
                    fake_spec = fake_spec[:needed]
                    fake_env = fake_env[:needed]
                    num_batch = needed
                synthetic_spec_list.append(fake_spec)
                synthetic_env_list.append(fake_env)
                current_generated += num_batch
                if current_generated >= num_to_generate:
                    break
            if current_generated >= num_to_generate:
                break

    if not synthetic_spec_list:
        return np.array([]), np.array([]), np.array([])

    synthetic_spec = np.concatenate(synthetic_spec_list, axis=0)
    synthetic_env = np.concatenate(synthetic_env_list, axis=0)
    synthetic_y = np.full(synthetic_spec.shape[0], y_minority[0])

    return synthetic_spec, synthetic_env, synthetic_y


"""ç¬¬ 2 éƒ¨åˆ†: åˆ†ç±»å™¨ä¸æŸå¤±å‡½æ•°æ¨¡"""


class SEBlock1D(nn.Module):
    """Squeeze-and-Excitation Block for 1D"""

    def __init__(self, channel, reduction=8):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool1d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, max(channel // reduction, 4), bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(max(channel // reduction, 4), channel, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1)
        return x * y.expand_as(x)


class CBAM1D(nn.Module):
    """Convolutional Block Attention Module for 1D"""

    def __init__(self, channel, reduction=8):
        super().__init__()
        self.channel_att = nn.Sequential(
            nn.AdaptiveAvgPool1d(1),
            nn.Conv1d(channel, channel // reduction, 1, bias=False),
            nn.ReLU(inplace=True),
            nn.Conv1d(channel // reduction, channel, 1, bias=False),
            nn.Sigmoid()
        )
        self.spatial_att = nn.Sequential(
            nn.Conv1d(2, 1, kernel_size=7, padding=3, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        ca = self.channel_att(x)
        x = x * ca
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        sa_input = torch.cat([avg_out, max_out], dim=1)
        sa = self.spatial_att(sa_input)
        x = x * sa
        return x


class SelfAttention1D(nn.Module):
    """Self-Attention for 1D sequences"""

    def __init__(self, in_dim):
        super().__init__()
        self.query = nn.Conv1d(in_dim, in_dim // 8, 1)
        self.key = nn.Conv1d(in_dim, in_dim // 8, 1)
        self.value = nn.Conv1d(in_dim, in_dim, 1)
        self.gamma = nn.Parameter(torch.zeros(1))

    def forward(self, x):
        B, C, L = x.size()
        Q = self.query(x).permute(0, 2, 1)  # (B, L, C/8)
        K = self.key(x)  # (B, C/8, L)
        V = self.value(x)  # (B, C, L)
        attn = torch.bmm(Q, K)  # (B, L, L)
        attn = F.softmax(attn / (K.size(1) ** 0.5), dim=-1)
        out = torch.bmm(V, attn.permute(0, 2, 1))  # (B, C, L)
        out = self.gamma * out + x
        return out


class FlexibleBranch1D(nn.Module):
    """1D CNNåˆ†æ”¯"""

    def __init__(self, in_channels, hidden_dim, attention_type='none', dropout=0.3):
        super().__init__()
        self.attention_type = attention_type
        self.conv_layers = nn.Sequential(
            nn.Conv1d(in_channels, hidden_dim // 2, kernel_size=3, padding=1),
            nn.BatchNorm1d(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Conv1d(hidden_dim // 2, hidden_dim, kernel_size=3, padding=1),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
        )
        if attention_type == 'se':
            self.attention = SEBlock1D(hidden_dim)
        elif attention_type == 'cbam':
            self.attention = CBAM1D(hidden_dim)
        elif attention_type == 'self':
            self.attention = SelfAttention1D(hidden_dim)
        else:
            self.attention = None
        self.pool = nn.AdaptiveAvgPool1d(8)

    def forward(self, x):
        x = self.conv_layers(x)
        if self.attention is not None:
            x = self.attention(x)
        x = self.pool(x)
        return x


class MultiFeatureFusionModel(nn.Module):
    """æ”¯æŒå¤šç‰¹å¾èåˆçš„æ¨¡å‹"""

    def __init__(self, n_spec_channels, n_env_channels,
                 spec_hidden=32, env_hidden=32, num_classes=6,
                 spec_attention='none', env_attention='none',
                 fusion_method='concat', dropout=0.3):
        super().__init__()
        self.fusion_method = fusion_method
        self.spec_branch = FlexibleBranch1D(
            n_spec_channels, spec_hidden, spec_attention, dropout
        )
        self.env_branch = FlexibleBranch1D(
            n_env_channels, env_hidden, env_attention, dropout
        )

        if fusion_method == 'concat' or fusion_method == 'weighted':  # 'weighted' åœ¨æ­¤å®ç°ä¸º concat
            fusion_dim = spec_hidden * 8 + env_hidden * 8
        elif fusion_method == 'add':
            raise NotImplementedError("Fusion method 'add' is not supported in this config")

        self.fusion = nn.Sequential(
            nn.Linear(fusion_dim, 128),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(dropout)
        )
        self.classifier = nn.Linear(64, num_classes)

    def forward(self, spec, env, return_features=False):
        spec_out = self.spec_branch(spec).flatten(1)
        env_out = self.env_branch(env).flatten(1)

        fused = torch.cat([spec_out, env_out], dim=1)
        features = self.fusion(fused)
        logits = self.classifier(features)

        if return_features:
            return logits, features
        return logits


class FocalLoss(nn.Module):
    """Focal Loss"""

    def __init__(self, alpha=0.25, gamma=2.0, class_weights=None):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.class_weights = class_weights

    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        if self.class_weights is not None:
            weights = self.class_weights[targets]
            ce_loss = ce_loss * weights
        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss
        return focal_loss.mean()


class LabelSmoothingCrossEntropy(nn.Module):
    """æ ‡ç­¾å¹³æ»‘äº¤å‰ç†µ"""

    def __init__(self, smoothing=0.1, class_weights=None):
        super().__init__()
        self.smoothing = smoothing
        self.class_weights = class_weights

    def forward(self, x, target):
        confidence = 1.0 - self.smoothing
        logprobs = F.log_softmax(x, dim=-1)
        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))
        nll_loss = nll_loss.squeeze(1)
        smooth_loss = -logprobs.mean(dim=-1)
        loss = confidence * nll_loss + self.smoothing * smooth_loss
        if self.class_weights is not None:
            loss = loss * self.class_weights[target]
        return loss.mean()


class CenterLoss(nn.Module):
    """Center Loss"""

    def __init__(self, num_classes, feature_dim, device):
        super().__init__()
        self.num_classes = num_classes
        self.feature_dim = feature_dim
        self.centers = nn.Parameter(torch.randn(num_classes, feature_dim).to(device))

    def forward(self, features, labels):
        batch_size = features.size(0)
        distmat = torch.pow(features, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \
                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()
        distmat.addmm_(features, self.centers.t(), beta=1, alpha=-2)
        classes = torch.arange(self.num_classes, device=features.device).long()
        labels_expand = labels.unsqueeze(1).expand(batch_size, self.num_classes)
        mask = labels_expand.eq(classes.expand(batch_size, self.num_classes))
        dist = distmat * mask.float()
        loss = dist.clamp(min=1e-12, max=1e+12).sum() / batch_size
        return loss


class CombinedLoss(nn.Module):
    """ç»„åˆæŸå¤±å‡½æ•°"""

    def __init__(self, num_classes, feature_dim, device,
                 loss_type='ce', use_label_smoothing=False, use_center_loss=False,
                 focal_alpha=0.25, focal_gamma=2.0, label_smoothing=0.1,
                 center_loss_weight=0.003, class_weights=None):
        super().__init__()
        self.use_center_loss = use_center_loss
        self.center_loss_weight = center_loss_weight
        if loss_type == 'focal':
            self.main_loss = FocalLoss(focal_alpha, focal_gamma, class_weights)
        elif use_label_smoothing:
            self.main_loss = LabelSmoothingCrossEntropy(label_smoothing, class_weights)
        else:
            self.main_loss = nn.CrossEntropyLoss(weight=class_weights)
        if use_center_loss:
            self.center_loss = CenterLoss(num_classes, feature_dim, device)

    def forward(self, logits, features, targets):
        main_loss = self.main_loss(logits, targets)
        if self.use_center_loss:
            center_loss = self.center_loss(features, targets)
            total_loss = main_loss + self.center_loss_weight * center_loss
            return total_loss
        return main_loss


def calculate_class_weights(y_train):
    """è®¡ç®—ç±»åˆ«æƒé‡"""
    class_counts = Counter(y_train)
    total = len(y_train)
    num_classes = len(class_counts)
    weights = torch.zeros(num_classes)
    for class_id, count in class_counts.items():
        if count > 0:
            weights[class_id] = total / (num_classes * count)
    return weights


"""ç¬¬ 3 éƒ¨åˆ†: èåˆçš„è®­ç»ƒä¸è¯„ä¼°é€»è¾‘"""


def run_augmentation_for_fold(spec_train, env_train, y_train, device, num_classes, gan_params, gan_epochs):
    """åœ¨å•æŠ˜çš„è®­ç»ƒé›†ä¸Šæ‰§è¡Œæ•°æ®å¢å¼º"""
    # print(f"  [Augmentation] å¯åŠ¨æŠ˜å†…æ•°æ®å¢å¼º...")

    # 1. æ‰¾åˆ°ç›®æ ‡æ ·æœ¬é‡ (è¯¥æŠ˜è®­ç»ƒé›†ä¸­çš„æœ€å¤§ç±»)
    class_counts = np.bincount(y_train)
    max_samples = np.max(class_counts)
    # print(f"  [Augmentation] å¹³è¡¡æ‰€æœ‰ç±»åˆ«è‡³ {max_samples} ä¸ªæ ·æœ¬ã€‚")

    # 2. å‡†å¤‡å­˜å‚¨åˆ—è¡¨ (é¦–å…ˆåŒ…å«æ‰€æœ‰åŸå§‹æ•°æ®)
    final_spec_list = [spec_train]
    final_env_list = [env_train]
    final_y_list = [y_train]

    # 3. éå†æ¯ä¸ªç±»åˆ«è¿›è¡Œå¢å¼º (å ä½ç¬¦ï¼Œå®é™…é€»è¾‘åœ¨ä¸‹é¢)
    for class_label in np.unique(y_train):
        class_mask = (y_train == class_label)
        num_samples = np.sum(class_mask)
        num_to_generate = max_samples - num_samples

        # if num_to_generate > 0:
        #     print(f"    - ç±»åˆ« {class_label}: æ ·æœ¬æ•° {num_samples}, éœ€ç”Ÿæˆ {num_to_generate} ...")
        # else:
        #     print(f"    - ç±»åˆ« {class_label}: æ ·æœ¬æ•° {num_samples} (å¤šæ•°ç±»)ï¼Œæ— éœ€ç”Ÿæˆã€‚")

    # 5. åœ¨æ•´ä¸ªæŠ˜è®­ç»ƒé›†ä¸Šè®­ç»ƒä¸€æ¬¡ VACWGAN
    print(f"  [Augmentation] æ­£åœ¨è®­ç»ƒ VACWGAN (Epochs={gan_epochs})...")
    # print(f"  [Augmentation] ä½¿ç”¨å‚æ•°: {gan_params}")
    fold_dataset = MultiModalDataset(spec_train, env_train, y_train)
    # ç¡®ä¿ batch_size ä¸å¤§äºæ€»æ ·æœ¬æ•°
    fold_batch_size = min(len(y_train), 64)
    fold_loader = DataLoader(fold_dataset, batch_size=fold_batch_size, shuffle=True)

    # ä¼ å…¥ä¸“å±çš„ gan_params å’Œ gan_epochs
    E, G, D, C = train_vacwgan(fold_loader, num_classes, device, gan_params, epochs=gan_epochs)
    # print(f"  [Augmentation] GAN è®­ç»ƒå®Œæ¯•ã€‚")

    # 6. å†æ¬¡å¾ªç¯ï¼Œè¿™æ¬¡ä»…ç”¨äºç”Ÿæˆ
    # print(f"  [Augmentation] æ­£åœ¨ç”Ÿæˆæ ·æœ¬...")
    for class_label in np.unique(y_train):
        class_mask = (y_train == class_label)
        x_spec_class = spec_train[class_mask]
        x_env_class = env_train[class_mask]
        y_class = y_train[class_mask]

        num_samples = len(y_class)
        num_to_generate = max_samples - num_samples

        if num_to_generate > 0:
            # 7. ç”Ÿæˆ (spec, env)
            syn_spec, syn_env, syn_y = generate_synthetic_samples(
                E, G, x_spec_class, x_env_class, y_class,
                num_to_generate, device
            )

            if len(syn_spec) > 0:
                # 8. (å·²ç§»é™¤ time_stats æ’è¡¥)
                # 9. æ·»åŠ åˆ°æœ€ç»ˆåˆ—è¡¨
                final_spec_list.append(syn_spec)
                final_env_list.append(syn_env)
                final_y_list.append(syn_y)

    # 10. æ‹¼æ¥æ‰€æœ‰æ•°æ®
    final_spec_train = np.concatenate(final_spec_list, axis=0)
    final_env_train = np.concatenate(final_env_list, axis=0)
    final_y_train = np.concatenate(final_y_list, axis=0)

    # print(f"  [Augmentation] æŠ˜å†…å¢å¼ºå®Œæˆã€‚è®­ç»ƒé›†è§„æ¨¡: {len(y_train)} -> {len(final_y_train)}")

    return final_spec_train, final_env_train, final_y_train


def train_single_fold(spec_train, env_train, y_train,
                      spec_val, env_val, y_val,
                      config, device, num_classes):
    """è®­ç»ƒå•ä¸ªæŠ˜çš„ MultiFeatureFusionModel"""

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_dataset = TensorDataset(
        torch.FloatTensor(spec_train),
        torch.FloatTensor(env_train),
        torch.LongTensor(y_train)
    )
    val_dataset = TensorDataset(
        torch.FloatTensor(spec_val),
        torch.FloatTensor(env_val),
        torch.LongTensor(y_val)
    )

    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)

    # åˆ›å»ºæ¨¡å‹
    model = MultiFeatureFusionModel(
        n_spec_channels=spec_train.shape[1],
        n_env_channels=env_train.shape[1],
        spec_hidden=config['spec_hidden'],
        env_hidden=config['env_hidden'],
        num_classes=num_classes,
        spec_attention=config['spec_attention'],
        env_attention=config['env_attention'],
        fusion_method=config['fusion_method'],
        dropout=config['dropout']
    ).to(device)

    # æŸå¤±å‡½æ•°
    class_weights = calculate_class_weights(y_train)
    criterion = CombinedLoss(
        num_classes=num_classes,
        feature_dim=64,  # èåˆåçš„ç‰¹å¾ç»´åº¦
        device=device,
        loss_type=config['loss_type'],
        use_label_smoothing=config['use_label_smoothing'],
        use_center_loss=config['use_center_loss'],
        focal_alpha=config.get('focal_alpha', 0.25),
        focal_gamma=config.get('focal_gamma', 2.0),
        label_smoothing=config.get('label_smoothing', 0.1),
        center_loss_weight=config.get('center_loss_weight', 0.003),
        class_weights=class_weights.to(device)
    )

    # ä¼˜åŒ–å™¨
    if config['optimizer'] == 'Adam':
        optimizer = optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])
    elif config['optimizer'] == 'AdamW':
        optimizer = optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])
    else:
        optimizer = optim.SGD(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'], momentum=0.9)

    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=config['scheduler_factor'], patience=config['scheduler_patience']
    )

    # è®­ç»ƒ
    best_val_acc = 0
    best_model_state = None
    patience = 0

    for epoch in range(TRAIN_EPOCHS):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        for spec, env, labels in train_loader:
            spec = spec.to(device)
            env = env.to(device)
            labels = labels.to(device)

            if np.random.random() < 0.5:
                noise_level = config.get('noise_level', 0.01)
                spec = spec + torch.randn_like(spec) * noise_level
                env = env + torch.randn_like(env) * noise_level

            optimizer.zero_grad()
            outputs, features = model(spec, env, return_features=True)
            loss = criterion(outputs, features, labels)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config['max_grad_norm'])
            optimizer.step()

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0
        val_correct = 0
        val_total = 0

        with torch.no_grad():
            for spec, env, labels in val_loader:
                spec = spec.to(device)
                env = env.to(device)
                labels = labels.to(device)
                outputs, features = model(spec, env, return_features=True)
                loss = criterion(outputs, features, labels)
                val_loss += loss.item()
                _, predicted = torch.max(outputs, 1)
                val_total += labels.size(0)
                val_correct += (predicted == labels).sum().item()

        val_acc = 100 * val_correct / val_total
        scheduler.step(val_loss)

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model_state = model.state_dict().copy()
            patience = 0
        else:
            patience += 1

        if patience >= EARLY_STOPPING_PATIENCE:
            break

    return best_val_acc, best_model_state


def cross_validate(spec_all, env_all, y_all, config, device, num_classes):
    """5 æŠ˜äº¤å‰éªŒè¯, å†…éƒ¨åŒ…å«æ•°æ®å¢å¼º"""
    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=1024) # ä¸€å®šè¦æ˜¯1024
    fold_accs = []
    fold_models = []

    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(spec_all, y_all)):
        print(f"\n--- Fold {fold_idx + 1}/{N_FOLDS} ---")

        # 1. åˆ’åˆ†æ•°æ®
        spec_train = spec_all[train_idx]
        env_train = env_all[train_idx]
        y_train = y_all[train_idx]

        spec_val = spec_all[val_idx]
        env_val = env_all[val_idx]
        y_val = y_all[val_idx]

        # 2. å½’ä¸€åŒ–
        # print("  [Normalization] æ­£åœ¨å½’ä¸€åŒ–...")
        spec_mean = spec_train.mean(axis=(0, 2), keepdims=True)
        spec_std = spec_train.std(axis=(0, 2), keepdims=True) + 1e-8
        spec_train_norm = (spec_train - spec_mean) / spec_std
        spec_val_norm = (spec_val - spec_mean) / spec_std

        env_mean = env_train.mean(axis=(0, 2), keepdims=True)
        env_std = env_train.std(axis=(0, 2), keepdims=True) + 1e-8
        env_train_norm = (env_train - env_mean) / env_std
        env_val_norm = (env_val - env_mean) / env_std

        # è·å–å½“å‰æŠ˜çš„ä¸“å±GANå‚æ•°
        gan_params_for_fold = FOLD_SPECIFIC_GAN_PARAMS[fold_idx]

        # 3. æ•°æ®å¢å¼º
        spec_train_aug, env_train_aug, y_train_aug = run_augmentation_for_fold(
            spec_train_norm, env_train_norm, y_train, device, num_classes,
            gan_params_for_fold, GAN_EPOCHS
        )

        # 4. ä½¿ç”¨å¢å¼ºåçš„è®­ç»ƒé›†å’ŒåŸå§‹éªŒè¯é›†è®­ç»ƒ
        print(f"  [Classifier Training] æ­£åœ¨è®­ç»ƒåˆ†ç±»å™¨ (Epochs={TRAIN_EPOCHS})...")
        fold_acc, fold_model_state = train_single_fold(
            spec_train_aug, env_train_aug, y_train_aug,
            spec_val_norm, env_val_norm, y_val,
            config, device, num_classes
        )
        print(f"  [Result] Fold {fold_idx + 1} éªŒè¯é›†å‡†ç¡®ç‡: {fold_acc:.2f}%")

        fold_accs.append(fold_acc)
        fold_models.append({
            'fold': fold_idx + 1,
            'accuracy': fold_acc,
            'model_state': fold_model_state,
            'n_train': len(y_train_aug),  # å¢å¼ºåçš„è®­ç»ƒé›†å¤§å°
            'n_val': len(y_val)
        })

    mean_acc = np.mean(fold_accs)
    std_acc = np.std(fold_accs)
    best_acc = np.max(fold_accs)

    return mean_acc, std_acc, best_acc, fold_accs, fold_models


class TopKTracker:
    """è¿½è¸ªå¹¶ä¿å­˜ Top-K æ¨¡å‹"""

    def __init__(self, k, save_dir):
        self.k = k
        self.save_dir = save_dir
        self.top_trials = []
        self.top_folds = []

    def update(self, mean_acc, trial_number, trial_info, fold_models):
        self.top_trials.append((mean_acc, trial_number, trial_info, fold_models))
        self.top_trials.sort(reverse=True, key=lambda x: x[0])
        self.top_trials = self.top_trials[:self.k]

        for fold_info in fold_models:
            self.top_folds.append((
                fold_info['accuracy'],
                trial_number,
                fold_info['fold'],
                fold_info
            ))
        self.top_folds.sort(reverse=True, key=lambda x: x[0])
        self.top_folds = self.top_folds[:self.k]
        self.save_top_k_info()

    def save_top_k_info(self):
        top_k_trials_info = []
        for rank, (mean_acc, trial_num, trial_info, fold_models) in enumerate(self.top_trials, 1):
            top_k_trials_info.append({
                'rank': rank,
                'trial_number': trial_num,
                'mean_accuracy': mean_acc,
                'std_accuracy': trial_info.get('std_acc', 0),
                'best_fold_accuracy': trial_info.get('best_acc', 0),
                'config': trial_info['config']
            })
        with open(f"{self.save_dir}/top_k_trials_info.json", 'w') as f:
            json.dump(top_k_trials_info, f, indent=2)

        top_k_folds_info = []
        for rank, (fold_acc, trial_num, fold_num, fold_info) in enumerate(self.top_folds, 1):
            top_k_folds_info.append({
                'rank': rank,
                'accuracy': fold_acc,
                'trial_number': trial_num,
                'fold_number': fold_num,
                'n_train': fold_info.get('n_train', 0),
                'n_val': fold_info.get('n_val', 0)
            })
        with open(f"{self.save_dir}/top_k_best_folds_info.json", 'w') as f:
            json.dump(top_k_folds_info, f, indent=2)

    def save_models(self):
        print(f"\n{'=' * 60}")
        print(f"ä¿å­˜Top-{self.k}æ¨¡å‹")
        print(f"{'=' * 60}")

        print(f"\n1ï¸âƒ£ Top-{self.k}è¯•éªŒçš„æœ€ä½³æŠ˜æ¨¡å‹:")
        for rank, (mean_acc, trial_num, trial_info, fold_models) in enumerate(self.top_trials, 1):
            best_fold = max(fold_models, key=lambda x: x['accuracy'])
            model_path = f"{self.save_dir}/top_trial{rank}_trial{trial_num}_mean{mean_acc:.2f}_best{best_fold['accuracy']:.2f}.pth"
            torch.save(best_fold['model_state'], model_path)
            print(f"  {rank}. Trial #{trial_num}: å¹³å‡={mean_acc:.2f}%, æœ€ä½³æŠ˜={best_fold['accuracy']:.2f}%")
            print(f"     æ–‡ä»¶: {os.path.basename(model_path)}")

        if len(self.top_trials) > 0:
            mean_acc, trial_num, trial_info, fold_models = self.top_trials[0]
            print(f"\n2ï¸âƒ£ æœ€ä½³è¯•éªŒ #{trial_num} çš„5æŠ˜æ¨¡å‹:")
            print(f"  {'æŠ˜æ•°':<8} {'å‡†ç¡®ç‡':<12} {'è®­ç»ƒé›†':<10} {'éªŒè¯é›†':<10} {'æ¨¡å‹è·¯å¾„':<60}")
            print(f"  {'-' * 100}")
            fold_details = []
            for fold_info in fold_models:
                fold_model_path = f"{self.save_dir}/best_trial_{trial_num}_fold{fold_info['fold']}_acc{fold_info['accuracy']:.2f}.pth"
                torch.save(fold_info['model_state'], fold_model_path)
                print(f"  Fold {fold_info['fold']:<3} {fold_info['accuracy']:>6.2f}%     "
                      f"{fold_info['n_train']:>6}æ ·æœ¬   {fold_info['n_val']:>6}æ ·æœ¬   "
                      f"{os.path.basename(fold_model_path)}")
                fold_details.append({
                    'fold': fold_info['fold'],
                    'accuracy': fold_info['accuracy'],
                    'n_train': fold_info['n_train'],
                    'n_val': fold_info['n_val'],
                    'model_path': fold_model_path
                })
            print(f"  {'-' * 100}")
            print(f"  å¹³å‡å‡†ç¡®ç‡: {mean_acc:.2f}%")
            print(f"  æ ‡å‡†å·®: {trial_info.get('std_acc', 0):.2f}%")
            best_trial_folds_info = {
                'trial_number': trial_num,
                'mean_accuracy': mean_acc,
                'std_accuracy': trial_info.get('std_acc', 0),
                'best_fold_accuracy': max(f['accuracy'] for f in fold_models),
                'config': trial_info['config'],
                'fold_details': fold_details
            }
            with open(f"{self.save_dir}/best_trial_all_folds_info.json", 'w') as f:
                json.dump(best_trial_folds_info, f, indent=2)

        print(f"\n3ï¸âƒ£ å…¨å±€Top-{self.k}æœ€ä½³éªŒè¯é›†å‡†ç¡®ç‡çš„foldæ¨¡å‹:")
        print(f"  {'æ’å':<6} {'å‡†ç¡®ç‡':<12} {'æ¥æº':<25} {'æ¨¡å‹è·¯å¾„':<60}")
        print(f"  {'-' * 110}")
        for rank, (fold_acc, trial_num, fold_num, fold_info) in enumerate(self.top_folds, 1):
            model_path = f"{self.save_dir}/top_fold{rank}_trial{trial_num}_fold{fold_num}_acc{fold_acc:.2f}.pth"
            torch.save(fold_info['model_state'], model_path)
            source_info = f"Trial #{trial_num}, Fold {fold_num}"
            print(f"  {rank:<6} {fold_acc:>6.2f}%     {source_info:<25} {os.path.basename(model_path)}")
        print(f"  {'-' * 110}")
        print(f"  è¯´æ˜: è¿™äº›æ˜¯æ‰€æœ‰è¯•éªŒæ‰€æœ‰foldä¸­éªŒè¯å‡†ç¡®ç‡æœ€é«˜çš„{self.k}ä¸ªæ¨¡å‹")


def objective(trial, spec_all, env_all, y_all, device, save_dir, top_k_tracker, num_classes):
    """Optunaç›®æ ‡å‡½æ•°"""
    config = {
        'spec_hidden': trial.suggest_categorical('spec_hidden', [16, 32, 64]),
        'env_hidden': trial.suggest_categorical('env_hidden', [16, 32, 64]),
        'spec_attention': trial.suggest_categorical('spec_attention', ['none', 'se', 'cbam', 'self']),
        'env_attention': trial.suggest_categorical('env_attention', ['none', 'se', 'cbam', 'self']),
        'fusion_method': trial.suggest_categorical('fusion_method', ['concat']),  # 'weighted' å’Œ 'add' æœªå®Œå…¨å®ç°
        'dropout': trial.suggest_float('dropout', 0.1, 0.5),
        'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64]),
        'lr': trial.suggest_float('lr', 1e-5, 1e-2, log=True),
        'weight_decay': trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True),
        'optimizer': trial.suggest_categorical('optimizer', ['Adam', 'AdamW', 'SGD']),
        'scheduler_factor': trial.suggest_float('scheduler_factor', 0.3, 0.8),
        'scheduler_patience': trial.suggest_int('scheduler_patience', 5, 15),
        'max_grad_norm': trial.suggest_float('max_grad_norm', 0.5, 2.0),
        'noise_level': trial.suggest_float('noise_level', 0.005, 0.05),
        'loss_type': trial.suggest_categorical('loss_type', ['ce', 'focal']),
        'use_label_smoothing': trial.suggest_categorical('use_label_smoothing', [True, False]),
        'use_center_loss': trial.suggest_categorical('use_center_loss', [True, False]),
        'focal_alpha': trial.suggest_float('focal_alpha', 0.1, 0.5),
        'focal_gamma': trial.suggest_float('focal_gamma', 1.0, 3.0),
        'label_smoothing': trial.suggest_float('label_smoothing', 0.05, 0.2),
        'center_loss_weight': trial.suggest_float('center_loss_weight', 0.001, 0.01, log=True),
    }

    try:
        print(f"\n{'=' * 60}")
        print(f"Trial {trial.number}")
        # print(f"  æ³¨æ„åŠ›: spec={config['spec_attention']}, env={config['env_attention']}")
        # print(f"  æŸå¤±å‡½æ•°: {config['loss_type']}, æ ‡ç­¾å¹³æ»‘={config['use_label_smoothing']}, Center Loss={config['use_center_loss']}")

        mean_acc, std_acc, best_acc, fold_accs, fold_models = cross_validate(
            spec_all, env_all, y_all, config, device, num_classes
        )

        print(f"  ç»“æœ: å¹³å‡={mean_acc:.2f}% (Â±{std_acc:.2f}%), æœ€ä½³={best_acc:.2f}%")
        print(f"  å„æŠ˜: {[f'{acc:.2f}%' for acc in fold_accs]}")
        print(f"{'=' * 60}")

        trial_info = {
            'trial_number': trial.number,
            'config': config,
            'mean_acc': mean_acc,
            'std_acc': std_acc,
            'best_acc': best_acc,
            'fold_accs': fold_accs
        }
        with open(f"{save_dir}/trial_{trial.number}_info.json", 'w') as f:
            json.dump(trial_info, f, indent=2)

        top_k_tracker.update(mean_acc, trial.number, trial_info, fold_models)

        return mean_acc

    except Exception as e:
        print(f"Trial {trial.number} å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 0.0


def main():
    try:
        with open(DATASET_PATH, 'rb') as f:
            dataset = pickle.load(f)
    except FileNotFoundError:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®é›†æ–‡ä»¶! è·¯å¾„: {DATASET_PATH}")
        return

    spec_all = dataset['x_train']['spec']
    env_all = dataset['x_train']['env']
    y_all = dataset['y_train']
    num_classes = len(np.unique(y_all))

    print(f"\næ•°æ®é›†ä¿¡æ¯:")
    print(f"  é¢‘è°±ç‰¹å¾: {spec_all.shape}")
    print(f"  åŒ…ç»œç‰¹å¾: {env_all.shape}")
    print(f"  æ ‡ç­¾: {y_all.shape} (å…± {num_classes} ä¸ªç±»åˆ«)")
    print(f"  æ€»æ ·æœ¬æ•°: {len(y_all)}")

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nä½¿ç”¨è®¾å¤‡: {device}")

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_dir = f"/AUGMENTED_SpecEnv_FoldGAN_opt_{timestamp}"
    Path(save_dir).mkdir(parents=True, exist_ok=True)
    print(f"ç»“æœä¿å­˜ç›®å½•: {save_dir}")

    top_k_tracker = TopKTracker(TOP_K_MODELS, save_dir)

    print(f"\nå¼€å§‹ä¼˜åŒ– (å…±{N_TRIALS}æ¬¡è¯•éªŒ, {N_FOLDS}æŠ˜äº¤å‰éªŒè¯)...")

    study = optuna.create_study(
        direction='maximize',
        sampler=optuna.samplers.TPESampler(seed=42),
        pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10)
    )

    study.optimize(
        lambda trial: objective(trial, spec_all, env_all, y_all, device, save_dir, top_k_tracker, num_classes),
        n_trials=N_TRIALS,
        show_progress_bar=True
    )

    print(f"\nâœ… ä¼˜åŒ–å®Œæˆ!")
    print(f"æœ€ä½³å¹³å‡å‡†ç¡®ç‡: {study.best_value:.2f}%")
    print(f"æœ€ä½³è¯•éªŒ: #{study.best_trial.number}")

    with open(f"{save_dir}/best_params.json", 'w') as f:
        json.dump(study.best_params, f, indent=2)
    with open(f"{save_dir}/best_trial_info.json", 'w') as f:
        json.dump({
            'trial_number': study.best_trial.number,
            'mean_acc': study.best_value,
            'params': study.best_params
        }, f, indent=2)

    print(f"\nå‡†å¤‡ä¿å­˜æ¨¡å‹...")
    top_k_tracker.save_models()

    print(f"\n{'=' * 60}")
    print("âœ… å®Œæˆ!")
    print(f"{'=' * 60}")
    print(f"\nç»“æœä¿å­˜åœ¨: {save_dir}")

    print(f"\nğŸ“Š Top-{TOP_K_MODELS}æ¨¡å‹æ€»è§ˆ:")
    print(f"{'æ’å':<6} {'è¯•éªŒå·':<10} {'å¹³å‡å‡†ç¡®ç‡':<15} {'æ ‡å‡†å·®':<12} {'æœ€ä½³æŠ˜':<12}")
    print(f"{'-' * 60}")
    if len(top_k_tracker.top_trials) > 0:
        for rank, (mean_acc, trial_num, trial_info, fold_models) in enumerate(top_k_tracker.top_trials, 1):
            print(f"{rank:<6} #{trial_num:<9} {mean_acc:>6.2f}%         "
                  f"Â±{trial_info.get('std_acc', 0):>4.2f}%      {trial_info.get('best_acc', 0):>5.2f}%")

        best_mean_acc, best_trial_num, best_trial_info, best_fold_models = top_k_tracker.top_trials[0]
        print(f"\nâ­ æœ€ä½³è¯•éªŒ #{best_trial_num} çš„5æŠ˜è¯¦ç»†å‡†ç¡®ç‡:")
        for fold_info in best_fold_models:
            print(f"  Fold {fold_info['fold']}: {fold_info['accuracy']:.2f}% (å¢å¼ºåè®­ç»ƒé›†å¤§å°: {fold_info['n_train']})")
    else:
        print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¯•éªŒç»“æœã€‚")

    if len(top_k_tracker.top_folds) > 0:
        print(f"\nğŸ“ˆ å…¨å±€Top-{TOP_K_MODELS}æœ€ä½³foldæ¥æº:")
        for rank, (fold_acc, trial_num, fold_num, _) in enumerate(top_k_tracker.top_folds, 1):
            print(f"  {rank}. {fold_acc:.2f}% â† Trial #{trial_num}, Fold {fold_num}")
    else:
        print("æœªæ‰¾åˆ°æœ€ä½³æŠ˜æ¨¡å‹ã€‚")


if __name__ == "__main__":
    main()
