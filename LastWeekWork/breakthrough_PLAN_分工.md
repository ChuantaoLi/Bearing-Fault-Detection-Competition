# 轴承故障诊断0.64→0.8+突破计划（纯数据驱动版）

## 核心策略：半监督为王 + 数据增强为本 + 集成为辅

### 🎯 关键洞察

- **无物理先验 = 第一名0.93也是纯数据驱动**
- **测试集1140样本 > 训练集860样本 → 伪标签是突破关键**
- **5折CV 0.65 vs 线上0.64 → 验证策略基本可靠**
- **每日有提交反馈 → 可以快速迭代验证**

---

## 阶段一：数据与特征重构（预期+5-8%）

### 1. 数据驱动的全频段特征挖掘（路遥）

**当前问题**：频段（430-3344Hz）和包络中心（1963-6891Hz）是随机搜索出的，可能遗漏关键判别特征

**纯数据驱动方案**：

- **类别判别性频段自动挖掘**：
  - 对6个类别分别计算FFT平均能量谱
  - 用互信息（Mutual Information）或Fisher判别比自动找出最具判别性的频段
  - 自动选择Top-10判别频段（替代当前固定7段）
- **全频段密集扫描**：
  - 低频：50-2000Hz（10段）
  - 中频：2000-5000Hz（10段）
  - 高频：5000-10240Hz（5段）→ 总计25段密集覆盖
- **自适应包络中心**：
  - 用聚类算法（K-Means）从训练集包络谱中自动提取能量聚集的中心频率
  - 自适应带宽：对每个中心在100-2000Hz范围网格搜索最佳带宽（最大化类间分离度）
  - 扩展到10-12个包络中心

**实现**：`data_driven_frequency_mining.py`（新建），修改`generate_optimized_dataset.py`

### 2. 训练集数据拼接增强 + 1024点多视角特征（张鑫源）

**明确约束**：测试集固定1024点 → 模型必须接受1024点输入

**训练集增强策略（仅训练阶段）**：

- **同类拼接切分**：
  - 将同类别的多个1024点样本拼接成长信号（如5个样本→5120点）
  - 用滑动窗口（步长512，50%重叠）重新切分成1024点窗口
  - 每个类别样本从100-180个 → 扩展到300-500个
- **好处**：增加训练样本多样性，但不改变模型输入维度

**1024点多视角特征提取（训练+测试通用）**：

**方案A：频域多分辨率（不改变时域长度）**

- 对同一1024点信号：
  - 短FFT（512点）：提取前512点，高时间分辨率
  - 标准FFT（1024点）：当前baseline
  - 长FFT（2048点）：1024点+补零，更密集频谱
- 3组频谱特征并行输入网络

**方案B：多粒度时域分割特征**

- 对1024点信号：
  - 全局特征：完整1024点提取
  - 局部特征：分成4段×256点，分别提取后池化
  - 滑动特征：用256步长滑动512点窗口，生成4个子窗口特征
- 多粒度特征融合

**方案C：多尺度池化（CNN内部）**

- 对1024点输入，CNN分支内使用：
  - Multi-scale Conv：kernel size = 3/5/7 并行
  - Multi-scale Pooling：pool size = 2/4/8 并行
  - 融合多尺度感受野

**实现**：`train_augmentation_concat.py`（训练集拼接），修改`generate_optimized_dataset.py`（多视角特征）

### 3. 🔥 爆炸式数据增强（10x扩展，最关键）（张鑫源）

**当前问题**：860个样本太少，当前只有0.01噪声增强

**暴力增强方案（每个样本→10个变体）**：

**时域增强（5种变体）**：

1. **时间平移**：随机shift ±10-30%窗口长度
2. **幅度缩放**：随机×0.7-1.3倍
3. **高斯噪声**：SNR=15/25/35dB三档，随机选择
4. **时间拉伸/压缩**：±5%速度变化（用scipy.signal.resample）
5. **随机裁剪+镜像补零**：裁剪80-95%，两端补零

**频域增强（3种变体）**：

1. **频谱掩码**：随机遮挡10-25%频段（SpecAugment）
2. **频率轴微扰**：±0.5%频率抖动（模拟转速波动）
3. **Mixup**：同类样本α混合（α~Beta(0.4, 0.4)）

**智能增强（难样本加倍）**：

- 识别5折CV中每个样本的平均置信度
- 对置信度<0.7的样本额外生成5个hard变体（更强噪声、更大扰动）
- 对混淆矩阵中易混淆类别对（如inner_broken vs inner_wear）专门生成混淆增强样本

**在线增强**：训练时每个epoch随机应用2-3种增强（概率0.7）

**实现**：`advanced_augmentation.py`（新建），集成到`train_optimized_features.py`

### 4. 降噪预处理升级

**答疑提示**：优先非参数/自适应方法

**实现方案**：

- **自适应小波降噪**：用'db4'小波多级分解，自适应阈值去噪
- **谱减法**：估计噪声功率谱，从信号谱中减去
- **可选SVD降噪**：对协方差矩阵SVD，保留前80%能量的成分

**实现**：`adaptive_denoising.py`（新建）

---

## 阶段二：模型架构升级（预期+3-5%）（张旺）

### 5. 多分支注意力融合架构

**当前问题**：特征融合只是简单concat，未自适应学习不同特征的重要性

**升级方案**：

- **Channel-wise Attention**：对spec/env/time_stats的每个通道学习权重（SENet风格）
- **Spatial-Temporal Attention**：在时序维度加权重要片段
- **Multi-Head Cross-Attention**：spec和env特征交互学习
- **Ghost Bottleneck**：减少参数防过拟合

**实现**：`attention_fusion_model.py`（新建）

### 6. 对抗训练与正则化

**目标**：提升鲁棒性和泛化能力

**方案**：

- **FGSM对抗样本**：训练时生成对抗扰动，混合训练（ratio=0.3）
- **Mixup/CutMix**：样本级混合（已在增强中）
- **更强Dropout**：从0.3提升到0.4-0.5
- **Label Smoothing**：从0.1提升到0.15-0.2

**实现**：修改`train_optimized_features.py`

### 7. 损失函数组合拳

**方案**：

- **主损失**：Focal Loss（处理难样本）或Label Smoothing CE
- **辅助损失1**：Triplet Loss（拉近同类，推远异类）
- **辅助损失2**：Center Loss（类内聚合）
- **组合权重**：主损失1.0 + Triplet 0.1 + Center 0.01

**实现**：`advanced_losses.py`（新建）

---

## 阶段三：半监督迭代突破（预期+5-10%，🔥决定性）（郑斐）

### 8. 🚀 测试集伪标签迭代（核心突破策略）

**为什么这是关键**：

- 测试集1140样本 vs 训练集860样本 → **增加57%数据量**
- 每日有反馈 → 可以验证伪标签质量
- 第一名0.93很可能用了这招

**三轮迭代方案**：

**🔥 第一轮：保守伪标签（目标+3-5%）**

1. 用当前最佳5折集成模型对测试集预测
2. 筛选**超高置信度样本**：
   - 5/5模型一致
   - 最高概率>0.95
   - 预期筛出300-400个样本（约30%）
3. 将伪标签样本加入训练集（860→1160+）
4. 重新5折CV训练（用增强后的数据）
5. **提交验证**：如果线上提升≥2%，进入第二轮

**⚡ 第二轮：中等置信度扩展（目标+2-3%）**

1. 根据第一轮反馈，分析错误样本模式
2. 降低阈值到0.90，筛选额外200-300个样本
3. **Co-Training策略**：
   - 训练两个不同架构（CNN vs Transformer-based）
   - 互相提供伪标签，只保留两者一致的
4. 重新训练，提交验证

**🎯 第三轮：全部覆盖+人工检查（冲刺0.80+）**

1. 对所有测试样本分配伪标签
2. 对低置信度样本（<0.7，约100-200个）：
   - 用模型分歧样本（5折预测不一致）
   - 可选人工检查（如果允许且时间充足）
3. 实现**Noisy Student**：
   - 教师模型：在干净数据+高置信伪标签上训练
   - 学生模型：更大网络+更强增强，在所有数据（含低置信）上训练
4. 最终集成：教师+学生的10折大集成

**风险控制**：

- 每轮迭代后必须做5折CV验证，本地提升≥1%才提交
- 保存每轮的训练checkpoint，如果线上掉点立即回滚
- 第一轮最保守，宁可少用也不引入错误

**实现**：`pseudo_labeling_iteration.py`（新建），`co_training.py`（新建）

### 9. 测试时增强（TTA）（李思德）

**方案**：

- 对每个测试样本生成8个轻微变体：
  - 原始×1
  - 微小时间shift×2（±5%）
  - 微小噪声（SNR=40dB）×2
  - 微小缩放（0.95/1.05）×2
  - 镜像翻转×1
- 5折模型×8变体 = 40次预测，投票或softmax平均
- **温度校准**（Temperature Scaling）：在验证集上优化温度参数T

**实现**：修改`test_ensemble_prediction.py`

### 10. 高级集成策略

**方案**：

- **Stacking元学习**：
  - 用5折模型的预测概率作为特征（5×6=30维）
  - 训练LightGBM元分类器
- **多架构集成**：
  - 当前CNN（baseline）
  - 1D-ResNet34（更深）
  - CNN-BiLSTM（捕捉长时序依赖）
  - 简化Transformer（Multi-Head Attention）
- **加权平均**：根据验证集准确率加权（表现好的权重更高）

**实现**：`stacking_ensemble.py`（新建），`additional_models.py`（ResNet/LSTM/Transformer）

---

## 🔥 执行优先级（按预期收益排序）

### Phase 1（立即执行，1-3天）

1. **爆炸式数据增强**（阶段一-3）→ 预期+3-4%
2. **测试集伪标签第一轮**（阶段三-8）→ 预期+3-5%

**理由**：这两项几乎不依赖其他改动，可以立即基于现有代码实现，预期合计+6-9%

### Phase 2（验证Phase1后，3-5天）

3. **训练集拼接增强**（阶段一-2）→ 预期+1-2%
4. **数据驱动频段挖掘**（阶段一-1）→ 预期+1-2%
5. **测试时增强TTA**（阶段三-9）→ 预期+1-2%

### Phase 3（冲刺阶段，5-7天）

6. **注意力融合模型**（阶段二-5）→ 预期+2-3%
7. **伪标签第二轮迭代**（阶段三-8）→ 预期+2-3%
8. **Stacking集成**（阶段三-10）→ 预期+1-2%




